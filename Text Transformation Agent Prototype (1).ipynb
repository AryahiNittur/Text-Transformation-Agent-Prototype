{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9efd01d-91a7-4aad-8bb6-1d414ff95f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your LangSmith API key (optional):  ········\n",
      "Enter your LangSmith Project Name (default = \"default\"):  ········\n",
      "Enter API key for OpenAI:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# input APIs and set up\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d7aff0f-ba19-46a0-8d81-d3e75a6a8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using prompt templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"\"\"You are a helpful assistant that transforms user text based on the following instructions:\n",
    "\n",
    "Inputs:\n",
    "- Translate: {translate}\n",
    "- Target Language: {target_language}\n",
    "- Summarize: {summary}\n",
    "- Tone: {tone}\n",
    "\n",
    "Behavior Rules:\n",
    "1. If Translate is True and the detected language ≠ target language, translate the text.\n",
    "2. If Translate is True and the detected language = target language, skip translation and explain why.\n",
    "3. If Summarize is True, summarize the original text (not the translated version).\n",
    "   - Apply the tone if provided:\n",
    "     - \"formal\": use precise and structured language.\n",
    "     - \"humorous\": be light, clever, and witty.\n",
    "     - \"casual\": use relaxed and conversational language.\n",
    "     - If no tone is given, use a neutral tone.\n",
    "4. If both Translate and Summarize are False, return the original text and explain that no transformation was applied.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c3a42d7-e96f-499e-a2b3-3d1d188d8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Translation? T/F T\n",
      "Enter target language: English\n",
      "Summary? T/F T\n",
      "Enter summary tone: witty\n"
     ]
    }
   ],
   "source": [
    "translate = input(\"Translation? T/F\")\n",
    "target_language = input(\"Enter target language:\")\n",
    "summary = input(\"Summary? T/F\") \n",
    "tone = input(\"Enter summary tone:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63a684d4-d54c-4b18-9873-791e79c891fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2425efd1-1f1a-459a-b0f7-3cf3758c5cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since both the translation and summarization requests are set to True, I'll go ahead and summarize the original text in a witty tone.\n",
      "\n",
      "Here's the summary:\n",
      "\n",
      "Once upon a time, a proud hare thought he could outpace his slowpoke tortoise buddy in a race. With confidence as high as his speed, he took a nap, just to wake up and find his friend plodding past the finish line. Turns out, slow and steady doesn’t just win the race; it also gives you plenty of time to catch up on some beauty sleep!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "prompt = prompt_template.invoke({\"translate\": translate, \"target_language\": target_language, \"summary\": summary, \n",
    "                                 \"tone\": tone, \"text\": \"\"\"Once, there was a hare who was best friends with a tortoise. \n",
    "                                 The hare was very proud of how fast he could run, so one day, \n",
    "                                 he challenged the tortoise to a race. The tortoise agreed, even though everyone \n",
    "                                 thought he was way too slow to win. The race began, and the hare raced so fast that he \n",
    "                                 was far ahead of the tortoise. Feeling confident, the hare decided to take a nap \n",
    "                                 under a tree while the tortoise kept going, step by step. When the hare woke up, \n",
    "                                 he was shocked to see the tortoise crossing the finish line. The tortoise had won the race!\"\"\"})\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfacec8-db4a-4758-a91c-6161965ac3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
